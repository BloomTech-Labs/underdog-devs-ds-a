{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vde8uo9v67lT"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The hope for the following code is that the mentees will be able to access\n",
        "some general conversation topics with respect to mentors handing down their\n",
        "knowledge and advice through feedback. A mentee might specify that they\n",
        "would like to see topics discussed purely in feedback produced by data\n",
        "science-centered conversations, or purely in web development-centered\n",
        "conversations, etc. The topicizer function currently accepts your list of\n",
        "documents(whatever each may pertain to), and will return either a grid \n",
        "with five topics represented by five words, or of chosen dimension.\n",
        "\"\"\"\n",
        "\n",
        "        \n",
        "# max_df allows us to ignore terms with a document frequency greater than .8\n",
        "tfidf_vect = TfidfVectorizer(max_df=.8, stop_words='english')\n",
        "\n",
        "def cleaner(text):\n",
        "    \"\"\"\n",
        "    Removes extra spaces, symbols, and punctuation from string.\n",
        "    \n",
        "    Parameters: text - string\n",
        "    Returns: a lowercased version of the string\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub('[^a-z A-Z0-9]', '', text)\n",
        "    text = re.sub('[ ]{2,}', ' ', text)\n",
        "\n",
        "    return text.lower().strip()\n",
        "\n",
        "\n",
        "def topicizer(texts, num_topics = 5, len_topic_repr = 5):\n",
        "    \"\"\"\n",
        "    Accepts a list of documents, cleans and transforms each document into a\n",
        "    dimensional vector, then uses non-negative matrix factorization along with\n",
        "    inverse document frequency, and singular value decomposition dimensionality\n",
        "    reduction, to return a list of topics.\n",
        "    Parameters:\n",
        "    \n",
        "      texts      - List of length two or greater. Each element in the list\n",
        "                   is a sequence of at least three space separated words, for\n",
        "                   a total of at least 10 unique words within the list.\n",
        "      num_topics - Positive integer. The number of topics to present the entire\n",
        "                   text. Will repeat topics if a large number is specified\n",
        "                   but there is not enough data.\n",
        "                  \n",
        "      len_topic_repr - Positive integer. The number of words that will be used\n",
        "                       to represent each topic.\n",
        "    Returns: A list of topic representations, each is a list\n",
        "             of the most influential words for the topic.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if len(texts) >= 2:\n",
        "        texts = [cleaner(x) for x in texts]\n",
        "        idfm = tfidf_vect.fit_transform(texts)\n",
        "        nmf = NMF(n_components=num_topics, random_state=42)\n",
        "        nmf.fit(idfm)\n",
        "        nmf_topics = []\n",
        "        for topic in nmf.components_:\n",
        "            s = topic.argsort()[-len_topic_repr:]\n",
        "            component_words = [tfidf_vect.get_feature_names_out()[i] for i in s]\n",
        "            nmf_topics += [component_words]\n",
        "        \n",
        "        return '\\n\\n'.join(' '.join(c) for c in nmf_topics)\n",
        "\n",
        "    return 'Not enough text to analyze'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NMF_Topic_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
