{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing docx2txt and sklearn\n",
    "[Anyone can use the Free Microsoft Office Online Link](https://www.microsoft.com/en-us/microsoft-365/free-office-online-for-the-web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import docx2txt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Word Documents from my Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery_job_description = ''' Bakery Assistant \n",
    "We are looking for a highly personable and enthusiastic bakery assistant to assist us at our baked goods counter. Your duties will include selling our baked goods to customers, managing baked goods and ingredient inventories, and taking control of the daily cleanup procedures at the bakery. You are also be required to monitor ingredient expiry dates.\n",
    "To ensure success, bakery assistants should exhibit experience in serving customers in a retail setting and a customer-oriented approach. Outstanding candidates are highly organized and have excellent communication skills.\n",
    "Bakery Assistant Responsibilities:\n",
    "Creating a welcoming and positive customer experience at the bakery counter.\n",
    "Advising customers on baked goods selection and taking orders.\n",
    "Weighing, pricing, and packaging purchased items, as well as processing payments.\n",
    "Managing the baking ingredients inventory and requesting the purchase of stock.\n",
    "Tracking ingredient expiry dates and arranging their use accordingly.\n",
    "Monitoring the visual appeal and the availability of baked goods on display.\n",
    "Reporting low baked goods stock to the Baker in a timely manner.\n",
    "Maintaining a clean and tidy baked goods counter and performing other duties on request.\n",
    "Cleaning the kitchen after business hours and preparing it for the next day.\n",
    "Managing customer complaints and relaying them to the Baker.\n",
    "Bakery Assistant Requirements:\n",
    "High school diploma or GED.\n",
    "Vocational training or baking coursework would be advantageous.\n",
    "State-approved food handling permit.\n",
    "Previous experience in serving customers in a bakery environment preferred.\n",
    "Proficiency in weighing, pricing, packaging, and processing payments of baked goods.\n",
    "Ability to manage ingredient inventories and to track expiry dates.\n",
    "A keen eye for detail and the ability to create visually appealing displays of baked goods.\n",
    "Knowledge of food and health industry regulations.\n",
    "Advanced ability to multitask and follow instructions given by bakers.\n",
    "Excellent customer service and communication skills.\n",
    "'''\n",
    "#bakery_job_description = docx2txt.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_job_description = ''' Senior Data Analyst- job post\n",
    "Southwest Texas Regional Advisory Council\n",
    "San Antonio, TX 78227\n",
    "$85,000 - $105,000 a year -  Full-time\n",
    "\n",
    "Job details\n",
    "Salary\n",
    "$85,000 - $105,000 a year\n",
    "Job Type\n",
    "Full-time\n",
    "Qualifications\n",
    "•\tEducation:\n",
    "•\tBachelor's (Preferred)\n",
    "•\tLocation:\n",
    "•\tSan Antonio, TX 78227 (Required)\n",
    "Benefits\n",
    "Pulled from the full job description\n",
    "Health insurance\n",
    "Dental insurance\n",
    "401(k)\n",
    "Flexible spending account\n",
    "Paid time off\n",
    "Vision insurance\n",
    "401(k) matching\n",
    "Life insurance\n",
    "Full Job Description\n",
    "The Senior Data Analyst assists the Division Director delivering data driven solutions to healthcare and public safety organizations. The candidate turns data into information, information into insight, and insight into actionable deliverables.\n",
    "•\tYou should have demonstrated experience with SQL, MySQL, and PostgreSQL databases including use of server tools. You will be part of a small cross-functional, agile team where you will have continued opportunity to learn and grow.\n",
    "•\tYou will help determine end user requirements, develop project plans, perform data functions, and create reports and visualizations. You will be responsible for system maintenance such as software updates, user management, data standardization, and system performance improvements.\n",
    "•\tWe look for self-starters who thrive in a fast-paced, agile environment – which means wearing many hats, being able to change direction quickly, and showing an eagerness to learn new technologies as the need arises. And most importantly – we look for people who can prioritize, multi-task, and deliver.\n",
    "Responsibilities \n",
    "•\tDevelop and maintain reports, dashboards, and data extraction routine\n",
    "•\tPerform data analysis, data validation, and data mapping/design\n",
    "•\tDevelop database queries, views, and stored procedures to support analytics\n",
    "•\tUse statistical methods to analyze data\n",
    "•\tDetermine user needs and design appropriate analytical solutions\n",
    "•\tAcquire, extract, transform, clean, and filter data\n",
    "•\tDevelop and update technical documentation including database documentation, standards, procedures and data dictionaries\n",
    "•\tMaintain detailed, tiered user accounts insuring proper data access\n",
    "•\tMaintain data analytics platforms and databases\n",
    "•\tProvide technical support and problem resolution for analytics platforms\n",
    "Qualifications \n",
    "· Undergraduate Degree (BA or BS) in Data Analytics, Statistics, or a relevant field from an accredited college or university\n",
    "· Minimum 3 years Tableau Server and Desktop development and maintenance experience required\n",
    "· Minimum 3 years database experience with a solid understanding of SQL, MySQL, and PostgreSQL databases\n",
    "· High level of mathematical and statistical knowledge\n",
    "· Accuracy and consistency when preparing reports\n",
    "· Understanding of database structure and data modeling\n",
    "· Adept at creating queries including quality assurance and optimization\n",
    "· Healthcare or Public Safety experience is highly desired\n",
    "· Ability to work independently with minimal supervision\n",
    "· Ability to work with time constraints and handle stressful situations\n",
    "· Strong attention to detail with sound judgement\n",
    "· Ability to collaborate and communicate effectively\n",
    "•\tAbility to work through ambiguity and deal with shifting priorities\n",
    "•\tAbility to mentor other analysts, as well as report to management.\n",
    "•\tProficiency in documenting processes\n",
    "Work Environment\n",
    "•\tYour choice between Mac or PC\n",
    "•\tWork provided phone\n",
    "•\tWork provided hotspot with unlimited data\n",
    "•\tStocked break room with complimentary snacks and drinks\n",
    "•\t401k with company match\n",
    "•\tWorks in multiple environments. Must possess physical and mental health to meet the demands of the position. Must be able to travel up to 25% and participate in various conferences, regional exercises, the Regional Medical Operations Center, and appropriate meetings related to state, regional emergency management and Acute Healthcare activities. Must be able to serve for extended periods of time, with high stress loads.\n",
    "Competencies \n",
    "•\tAnalytical - Collects / researches data; Uses intuition and experience to supplement data.\n",
    "•\tProblem Solving - Identifies and resolves problems in a timely manner; Gathers and analyzes information skillfully; Develops alternative solutions.\n",
    "•\tProject Management - Develops project plans; Communicates changes and progress; Completes projects on time and within budget.\n",
    "•\tOral Communication - Speaks clearly and persuasively; Listens and gets clarification when needed; Responds well to questions; Contributes thoughts, ideas and suggestions.\n",
    "•\tWritten Communication - Writes clearly and informatively; Edits work; Varies writing style to meet needs; Presents numerical data effectively; Able to read and interpret written information.\n",
    "•\tTeamwork - Balances team and individual responsibilities; Exhibits objectivity and openness to others' views; Gives and solicits feedback.\n",
    "•\tQuality Management - Looks for ways to improve and promote quality; Demonstrates accuracy and thoroughness.\n",
    "•\tBusiness Acumen - Understands business implications of decisions; Demonstrates knowledge of market and competition; Aligns work with strategic goals.\n",
    "•\tJudgment - Exhibits sound and accurate judgment; Supports and explains reasoning for decisions; Includes appropriate people in decision-making process.\n",
    "•\tPlanning/Organizing - Prioritizes and plans work activities; Sets goals and objectives.\n",
    "•\tQuality - Demonstrates accuracy and thoroughness; Looks for ways to improve and promote quality; Applies feedback to improve performance.\n",
    "Code of Conduct: \n",
    "Employee follows the STRAC Code of Conduct, which are rules to guide us in our work to assure the highest standards of business ethics and compliance as follows:\n",
    "1. Legal Compliance: comply with federal/state laws\n",
    "2. Business Ethics: accurately & honestly represent the Organization and not defraud anyone of money, property or service.\n",
    "3. Confidentiality: protect confidential information\n",
    "4. Conflict of Interest: do not use position to profit personally\n",
    "5. Business Relationships: business transactions are free from offers or solicitation of gifts/favors\n",
    "6. Protection of Assets: preserve assets by using resources prudently and effectively\n",
    "7. Patient Rights: respect and support patient rights to privacy & treatment\n",
    "About the Southwest Texas Regional Advisory Council \n",
    "The Southwest Texas Regional Advisory Council (STRAC) is designated by the Texas Department of State Health Services (DSHS) to develop, implement and maintain a regional trauma and emergency healthcare system for the 22 counties in Trauma Service Area P. TSA-P has a mixture of urban, suburban, rural and frontier counties, including the 7th largest city in the United\n",
    "States to the International Border with Mexico. The region encompasses over 26,000 square miles in southwest Texas. STRAC is one of twenty-two regional advisory councils in Texas that comprise the Texas Trauma and Emergency Healthcare System.\n",
    "The Southwest Texas Regional Advisory Council, together with its leadership, members and staff, strives to maintain its reputation as a preeminent leader in regional healthcare coordination within Texas and across the United States. Working collaboratively alongside EMS providers, hospital and healthcare system leadership, as well as local governments, STRAC leverages its consensus based approach to innovative program development that has led to cutting edge improvements in regional emergency healthcare, including its Regional Prehospital\n",
    "Whole Blood Program, Regional Communication and Coordination Center (MEDCOM), Mental\n",
    "Health Patient Navigation System alongside our Law Enforcement Partners and the Texas\n",
    "Emergency Medical Task Force.\n",
    "STRAC is a 501c3 non-profit, tax-exempt member organization consisting of 74 general and specialty hospitals, including 2 Level I Trauma Centers, 16 PCI centers, 12 Stroke centers, air medical providers, and over 70 Fire and EMS agencies.'\n",
    "'\n",
    "Work Location:\n",
    "•\tOne location\n",
    "Job Type: Full-time\n",
    "Pay: $85,000.00 - $105,000.00 per year\n",
    "Benefits:\n",
    "•\t401(k)\n",
    "•\t401(k) matching\n",
    "•\tDental insurance\n",
    "•\tFlexible spending account\n",
    "•\tHealth insurance\n",
    "•\tLife insurance\n",
    "•\tPaid time off\n",
    "•\tVision insurance\n",
    "Schedule:\n",
    "•\t8 hour shift\n",
    "•\tMonday to Friday\n",
    "•\tOn call\n",
    "Education:\n",
    "•\tBachelor's (Preferred)\n",
    "Location:\n",
    "•\tSan Antonio, TX 78227 (Required)\n",
    "Work Location: One location\n",
    "Hiring Insights\n",
    "Hiring 1 candidate for this role\n",
    "Urgently hiring\n",
    "Job activity\n",
    "Employer reviewed job 4 days ago\n",
    "Posted 30+ days ago\n",
    "30+ days ago\n",
    "If you require alternative methods of application or screening, you must approach the employer directly to request this as Indeed is not responsible for the employer's application process.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume1 = '''Juan Jose Carin \n",
    "Mountain View, CA 94041 650-336-4590 | juanjose.carin@gmail.com Data Scientist linkedin.com/in/juanjosecarin | juanjocarin.github.io \n",
    "\n",
    "Professional Profile \n",
    "Passionate about data analysis and experiments, mainly focused on user behavior, experience, and engagement, with a solid background in data science and statistics, and extensive experience using data insights to drive business growth. \n",
    "Education \n",
    "\n",
    "2016 University of California, Berkeley Master of Information and Data Science \n",
    "• Machine Learning\n",
    "• Machine Learning at Scale \n",
    "• Data Visualization and Communication \n",
    "• Research Design and Applications for \n",
    "GPA: 3.93 \n",
    " \n",
    "Relevant courses: \n",
    "• Field Experiments\n",
    "• Applied Regression and Time Series \n",
    "Analysis \n",
    "• Storing and Retrieving Data \n",
    "• Exploring and Analyzing Data \n",
    "Data Analysis \n",
    "2014 \n",
    "Universidad Politécnica de Madrid M.S. in Statistical and Computational Information Processing \n",
    "• Data Mining\n",
    "• Multivariate Analysis • Time Series \n",
    "• Monte Carlo Techniques\n",
    "• Numerical Methods in Finance • Stochastic Models in Finance • Bayesian Networks \n",
    "GPA: 3.69 \n",
    "Relevant courses: \n",
    "• Neural Networks and Statistical Learning \n",
    "• Regression and Prediction Methods • Optimization Techniques \n",
    "2005 \n",
    "Universidad Politécnica de Madrid M.S. in Telecommunication Engineering \n",
    "GPA: 3.03 \n",
    "Focus Area: Radio communication systems (radar and mobile).\n",
    "Fellowship: First year at University, due to Honors obtained last year at high school. \n",
    "Skills \n",
    "Experience \n",
    "DATA SCIENCE \n",
    "\n",
    "Proficient: Intermediate: Basic: \n",
    "Programming / Statistics R, Python, SQL\n",
    "SPSS, SAS, Matlab EViews, Demetra+ \n",
    "Big Data\n",
    "Hadoop, Hive, MrJob Spark, Storm \n",
    "Visualization \n",
    "Tableau D3.js \n",
    "Others\n",
    "Git, AWS\n",
    "Bash\n",
    "Gephi, Neo4j, QGIS \n",
    "\n",
    "Jan. 2016 – Mar. 2016 \n",
    "Data Scientist \n",
    "CONENTO \n",
    "Madrid, Spain (working remotely) \n",
    "Jun. 2014 – Sep. 2014 \n",
    "• Designed and implemented the ETL pipeline for a predictive model of traffic on the main roads in eastern Spain (a project for the Spanish government). \n",
    "• Automated scripts in R to extract, transform, clean (incl. anomaly detection), and load into MySQL data from multiple data sources: road traffic sensors, accidents, road works, weather. \n",
    "Data Scientist \n",
    "CONENTO \n",
    "Madrid, Spain \n",
    "•\tDesigned an experiment for Google Spain (conducted in October 2014) to measure the impact of YouTube ads on the sales of a car manufacturer's dealer network. \n",
    "•\tA matched-pair, cluster-randomized design, which involved selecting the test and control groups from a sample of 50+ cities in Spain (where geo-targeted ads were possible) based on their sales- wise similarity over time, using wavelets (and R). \n",
    "MANAGEMENT – SALES (Electrical Eng.) \n",
    "\n",
    "Feb. 2009 – Aug. 2013 Head of Sales, Spain & Portugal – Test &Measurement dept. \n",
    "YOKOGAWA \n",
    "Madrid, Spain \n",
    "• Applied analysis of sales and market trends to decide the direction of the department. • Led a team of 7 people. \n",
    "1 of 2 \n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume2 = ''' John A Baker Jr.\n",
    "Data Scientist | Machine Learning Engineer\n",
    "San Antonio, TX | (619) 392-1231 | baker.john20@yahoo.com | johnabakerjr.link | GitHub: JohnBaker | LinkedIn: JohnBaker\n",
    "TECHNICAL SKILLS\n",
    " \n",
    "Development: Python (NumPy, Pandas, Scikit-learn), SQL, Tableau, PyTorch, Keras, Spark, Flask, Plotly Dash, Heroku\n",
    "Data Science: TensorFlow, Matplotlib, Data Analysis/Cleaning, Predictive Analytics, Machine Learning, Neural Networks\n",
    "Expertise: Project Management, Business Development, Technical Sales, Real Estate, Digital Marketing, Data Collection\n",
    "PROJECTS\n",
    " \n",
    "Plotly/Dash app, Life Expectancy Animation (1952-2007) - Data Scientist/Programmer, Heroku\t2021\n",
    "Plotly/Dash app, Life Expectancy SunBurst (2007) - Data Scientist/Programmer, Heroku\t2021\n",
    "●\tResearched the life expectancy data from Kaggle to understand and predict how different features affect longevity.\n",
    "●\tDecided on which animation features could be used to produce a fully interactive visualization of the data analysis. ● Built scatter plot apps using Plotly Dash to allow users to see how GDP correlates with life expectancy long-term.\n",
    "Custom Tableau Project, Fully Interactive Business Dashboard - Data Scientist/Programmer, Tableau Public\t2021 ● Researched the stock data that is associated with Tableau to evaluate and understand data for implementation.\n",
    "●\tDecided appropriate resource and tool to use to create a fully functional site that displayed results found.\n",
    "●\tBuilt a dashboard that shows total sales for each region, total profit, total orders,  daily sales, and much more.\n",
    "EXPERIENCE\n",
    " \n",
    "Underdog Devs, Remote - Machine Learning Engineer, Underdogdevs\t2022 - 2022\n",
    "●\tWorked in a team environment to make foundational decisions about the development of the product.\n",
    "●\tBuilt real software for a real cause organization, using Trello and GitHub to track all product development.\n",
    "●\tGained experience in database, machine learning, and visualizations as a collaborative exercise, where team members contributed their skills, experience, and time to collectively create a product.\n",
    "Combat Realty, Chula Vista, CA - Broker/Owner\t2013 - 2020\n",
    "●\tUsed the proprietary information of the company to analyze and collect customer data to increase business.\n",
    "●\tPerformed data integrity on all customers accounts and ensured the data was safe and secure at all times.\n",
    "●\tTrained, and coached a team of 9 to 12 on how to properly store data and stay compliant without data breach.\n",
    "●\tMarketed the residential real estate business via digital/social campaigns, lead generation, and cold calling.\n",
    "●\tPerformed payroll duties weekly for sales associates and salaried employees and corrected any discrepancies.\n",
    "Prudential California Realty, Chula Vista, CA - Salesperson\t2009 - 2013\n",
    "●\tCollected customer data and accurately wrote real estate contracts for sales and leases.\n",
    "●\tFostered a positive work environment with 3 owners, 40+ coworkers, brokers, and salespeople with no complaints.\n",
    "●\tPerformed more than 100-300 cold calls per day and understood the customers housing needs to make the sales.\n",
    "EDUCATION\n",
    " \n",
    "BloomTech (Lambda School), Data Science\t2021 - 2022\n",
    "● Immersive curriculum focused on predictive modeling, data engineering, machine learning, and computer science.\n",
    "San Diego City College, Real Estate\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning the job description and resume into a list\n",
    "- First, we compared a bakery job to data science resume 1. <br/>\n",
    "- Second, we compared a bakery job to data science resume 2. <br/>\n",
    "- Third, we compared a data science job to data science resume 1. <br/>\n",
    "- Forth, we compared a data science job to data science resume 2. <br/>\n",
    "- Fifth, we compared the bakery job to the bakery job. <br/>\n",
    "- Sixth, we compared the data science job to the data science job. <br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery_Data1 = [bakery_job_description, resume1]\n",
    "bakery_Data2 = [bakery_job_description, resume2]\n",
    "data_Data1 = [data_job_description, resume1]\n",
    "data_Data2 = [data_job_description, resume2]\n",
    "bakery_bakery = [bakery_job_description, bakery_job_description]\n",
    "data_Data = [data_job_description, data_job_description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We made a Count Vectorizer\n",
    "CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix.\n",
    "### We fit and transformed all the data\n",
    "This method performs fit and transform on the input data at a single time and converts the data points. If we use fit and transform separate when we need both then it will decrease the efficiency of the model so we use fit_transform() which will do both fit and transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "matrix_bakery_Data1 = cv.fit_transform(bakery_Data1)\n",
    "matrix_bakery_Data2 = cv.fit_transform(bakery_Data2)\n",
    "matrix_data_Data1 = cv.fit_transform(data_Data1)\n",
    "matrix_data_Data2 = cv.fit_transform(data_Data2)\n",
    "matrix_bakery_bakery = cv.fit_transform(bakery_bakery)\n",
    "matrix_data_Data = cv.fit_transform(data_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we take the cosine similarity\n",
    "Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. We are using it to measure document similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_bakery_Data1 = cosine_similarity(matrix_bakery_Data1)\n",
    "similarity_matrix_bakery_Data2 = cosine_similarity(matrix_bakery_Data2)\n",
    "similarity_matrix_data_Data1 = cosine_similarity(matrix_data_Data1)\n",
    "similarity_matrix_data_Data2 = cosine_similarity(matrix_data_Data2)\n",
    "similarity_matrix_bakery_bakery = cosine_similarity(matrix_bakery_bakery)\n",
    "similarity_matrix_data_Data = cosine_similarity(matrix_data_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the results\n",
    "The results of the bakery job compared to the data science resume were not encouraging. We were hoping to get back a lower score. The results show what we already knew, this is not a perfect way to do it. Although, a score of over 60% when compared to a job you made your resume for, could be a good indicator that you should at least try to get the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data resume #1 matches baking job By: 51%\n",
      "Data resume #2 matches baking job By: 52%\n",
      "Data resume #1 matches data job By: 65%\n",
      "Data resume #2 matches data job By: 67%\n",
      "Data job matches data job By: 100%\n",
      "Data job matches data job By: 100%\n"
     ]
    }
   ],
   "source": [
    "print('Data resume #1 matches baking job By: '+ str(round(similarity_matrix_bakery_Data1[1][0]*100))+ '%')\n",
    "print('Data resume #2 matches baking job By: '+ str(round(similarity_matrix_bakery_Data2[1][0]*100))+ '%')\n",
    "print('Data resume #1 matches data job By: '+ str(round(similarity_matrix_data_Data1[1][0]*100))+ '%')\n",
    "print('Data resume #2 matches data job By: '+ str(round(similarity_matrix_data_Data2[1][0]*100))+ '%')\n",
    "print('Data job matches data job By: '+ str(round(similarity_matrix_bakery_bakery[1][0]*100))+ '%')\n",
    "print('Data job matches data job By: '+ str(round(similarity_matrix_data_Data[1][0]*100))+ '%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20febc02521689004c63a7e5dea71165f7f03c1a736a22ce773be47e973f4491"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('underdog-devs-ds-a-1ez0ku27')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
